{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d67ee3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all the libraries required\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import shutil\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tq\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils import clip_grad_value_\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2b0a7f",
   "metadata": {
    "code_folding": [
     0,
     7,
     10,
     13,
     65
    ]
   },
   "outputs": [],
   "source": [
    "# Functions and Modules, utilities and DataLoaders\n",
    "# DataLoader is for loading training dataset\n",
    "# Testloader is used for loading test files, while predicting or denoising individual files\n",
    "\n",
    "def printDiagram(model, data, location):\n",
    "    import hiddenlayer as hl\n",
    "    transforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n",
    "    graph = hl.build_graph(model, data, transforms=transforms)\n",
    "    graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "    graph.save(location, format='png')\n",
    "\n",
    "def updateColor(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def reformatTensor2Image(tensor):\n",
    "     return torch.permute(tensor, (1, 2, 0)).cpu().detach().numpy()\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.cacheX = []\n",
    "        self.cacheY = []\n",
    "        self.cacheInfo = ''\n",
    "        \n",
    "    def loadVideo(self, dataDirectory, dataInfo, cached=0):\n",
    "        if cached==1:\n",
    "            with open('x.pickle', 'rb') as fp:\n",
    "                self.cacheX = pickle.load(fp)\n",
    "            with open('y.pickle', 'rb') as fp:\n",
    "                self.cacheY = pickle.load(fp)\n",
    "        else:\n",
    "            for i in tq.tqdm( dataInfo.index ) :\n",
    "                if dataInfo['frames'][i] == 100:\n",
    "                    location = dataDirectory + dataInfo['dirname'][i]\n",
    "                    cacheX, cacheY = [], []\n",
    "                    inPath = glob.glob( location + '/input/*.jpg' )\n",
    "                    outPath = glob.glob( location + '/GT/*.jpg' )\n",
    "\n",
    "                    for img in (inPath):\n",
    "                        cacheX.append( updateColor( cv2.resize( cv2.imread(img), (640, 360) ) ) )\n",
    "                    for img in (outPath):\n",
    "                        cacheY.append( updateColor( cv2.resize( cv2.imread(img), (640, 360) ) ) )\n",
    "                    self.cacheX.append(cacheX)\n",
    "                    self.cacheY.append(cacheY)\n",
    "        \n",
    "    def loadUnit(self, index, offset):\n",
    "        \n",
    "        lb = max(0, offset - 5)\n",
    "        rb = min(offset + 5, len(self.cacheX[index]) - 1)\n",
    "        padleft = max(0, 5 - offset)\n",
    "        padright = max(0, 5 - (len(self.cacheX[index])-1 - offset))\n",
    "        \n",
    "        #print(lb, rb, padleft, padright, len(self.cacheX[index]))\n",
    "        X = [self.cacheX[index][lb]] * padleft + self.cacheX[index][lb: rb+1] + [self.cacheX[index][rb]] * padright\n",
    "        Y = self.cacheY[index][offset] \n",
    "        \n",
    "        return X, Y\n",
    "    \n",
    "    def loadBatch(self, xrange, offset):\n",
    "        X, Y = [], []\n",
    "        for i in range(xrange[0], xrange[1]):\n",
    "            tempX, tempY = self.loadUnit(i, offset)\n",
    "            X.append(tempX)\n",
    "            Y.append(tempY)\n",
    "        X, Y = np.array(X).astype('float32')/255, np.array(Y).astype('float32')/255\n",
    "        tensorX, tensorY = torch.tensor(X).to(device), torch.tensor(Y).to(device)\n",
    "        tensorX, tensorY = tensorX.permute( (0, 4, 1, 2, 3)), tensorY.permute( (0, 3, 1, 2) )\n",
    "        return tensorX, tensor\n",
    "    \n",
    "class TestLoader():\n",
    "    def __init__(self, location, device):\n",
    "        self.device = device\n",
    "        self.cacheX = []\n",
    "        self.counter = 0\n",
    "        self.cacheInfo = ''\n",
    "        inPath = glob.glob( location + '/*.jpg' )\n",
    "        for img in (inPath):\n",
    "            self.counter = self.counter + 1\n",
    "            self.cacheX.append( cv2.cvtColor( cv2.resize( cv2.imread(img), (640, 360) ), cv2.COLOR_BGR2RGB) ) \n",
    "    \n",
    "    def getCountOfFrames(self):\n",
    "        return self.counter\n",
    "            \n",
    "    def loadUnit(self, offset):\n",
    "        if offset >= self.counter or offset < 0:\n",
    "            return False\n",
    "        lb = max(0, offset - 5)\n",
    "        rb = min(offset + 5, len(self.cacheX) - 1)\n",
    "        padleft = max(0, 5 - offset)\n",
    "        padright = max(0, 5 - (len(self.cacheX)-1 - offset))\n",
    "        \n",
    "        X = [self.cacheX[lb]] * padleft + self.cacheX[lb: rb+1] + [self.cacheX[rb]] * padright\n",
    "        X = np.array(X).astype('float32')/255\n",
    "        \n",
    "        tensorX = torch.tensor(X).to(device)\n",
    "        tensorX = tensorX.permute( (3, 0, 1, 2))\n",
    "        return torch.unsqueeze(tensorX, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e89319",
   "metadata": {
    "code_folding": [
     2,
     62,
     78
    ]
   },
   "outputs": [],
   "source": [
    "#  Neural Network Architecture\n",
    "\n",
    "class AutoEncoder4(nn.Module):\n",
    "    def __init__(self,channels=[7, 8, 16, 24, 30] ):\n",
    "        super(AutoEncoder4, self).__init__()\n",
    "        self.mpool = nn.MaxPool2d((2, 2))\n",
    "        self.upsamp = nn.Upsample(scale_factor=(2, 2))\n",
    "        self.mpoolodd = nn.MaxPool2d((3, 2))\n",
    "        self.upsampodd = nn.Upsample(scale_factor=(3, 2))\n",
    "        \n",
    "        self.sigmoid, self.relu = nn.Sigmoid(), nn.ReLU()\n",
    "        \n",
    "        self.conv1  = nn.Conv2d(in_channels=channels[0], out_channels=channels[1], kernel_size=(3, 3), padding=1)\n",
    "        self.bn1    = nn.BatchNorm2d(num_features=channels[1])\n",
    "        self.conv2 = nn.Conv2d(in_channels=channels[1], out_channels=channels[2], kernel_size=(3, 3), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=channels[2])\n",
    "        self.conv3 = nn.Conv2d(in_channels=channels[2], out_channels=channels[3], kernel_size=(3, 3), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=channels[3])\n",
    "        self.conv4 = nn.Conv2d(in_channels=channels[3], out_channels=channels[4], kernel_size=(3, 3), padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=channels[4])\n",
    "        \n",
    "        self.deconv4 = nn.ConvTranspose2d(in_channels=channels[4], out_channels=channels[3], kernel_size=(3, 3), padding=1 )\n",
    "        self.rbn4 = nn.BatchNorm2d(num_features=channels[3])\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels=channels[3], out_channels=channels[2], kernel_size=(3, 3), padding=1 )\n",
    "        self.rbn3 = nn.BatchNorm2d(num_features=channels[2])\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=channels[2], out_channels=channels[1], kernel_size=(3, 3), padding=1 )\n",
    "        self.rbn2 = nn.BatchNorm2d(num_features=channels[1])\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=channels[1], out_channels=channels[0], kernel_size=(3, 3), padding=1 )\n",
    "        self.rbn1 = nn.BatchNorm2d(num_features=channels[0])\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.conv3.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.conv4.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.deconv1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.deconv2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.deconv3.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.deconv4.weight)\n",
    "        \n",
    "    def forward(self, in_batch):\n",
    "\n",
    "        encoded  = self.relu( self.bn1( self.conv1(in_batch) ) )\n",
    "        \n",
    "        encoded2 = self.mpool(encoded)\n",
    "        encoded2 = self.relu( self.bn2( self.conv2(encoded2 ) ) )\n",
    "        \n",
    "        encoded3 = self.mpoolodd(encoded2)\n",
    "        encoded3 = self.relu( self.bn3(self.conv3(encoded3 ) ) )\n",
    "        \n",
    "        encoded4 = self.relu( self.bn4(self.conv4(encoded3 ) ) )\n",
    "        \n",
    "        decoded4 = self.relu( self.rbn4( self.deconv4(encoded4) ) + encoded3 )\n",
    "        decoded4 = self.upsampodd(decoded4)\n",
    "        \n",
    "        decoded3 = self.relu( self.rbn3( self.deconv3(decoded4) ) + encoded2 )\n",
    "        decoded3 = self.upsamp(decoded3)\n",
    "        \n",
    "        decoded2 = self.relu( self.rbn2( self.deconv2(decoded3) ) + encoded )\n",
    "        decoded2 = self.relu(decoded2)\n",
    "        \n",
    "        return self.relu( self.rbn1( self.deconv1(decoded2) ) + in_batch )\n",
    "\n",
    "class DenoiserStackConv(nn.Module):\n",
    "    def __init__(self,channels=[7,8,16,24,30]):\n",
    "        super(DenoiserStackConv, self).__init__()\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.mpool3d = nn.MaxPool3d((2, 2, 2))\n",
    "        \n",
    "        self.globalmpool1 = nn.MaxPool3d( (11, 1, 1) )\n",
    "        self.globalmpool2 = nn.MaxPool3d( (4, 1, 1) )\n",
    "        \n",
    "        self.upsample     = nn.Upsample(scale_factor= (2, 2) )\n",
    "        \n",
    "        self.conv3d1      = nn.Conv3d(3, 6, (3, 3, 3), padding=(0, 1, 1))\n",
    "        self.conv3d2      = nn.Conv3d(6, 8, (3, 3, 3), padding=(0, 1, 1))\n",
    "\n",
    "        self.parNet       = AutoEncoder4( [8, 16, 30, 36, 64 ])\n",
    "\n",
    "        self.conv1        = nn.Conv2d(in_channels=8, out_channels=6, kernel_size=(3, 3),padding=1)\n",
    "        self.conv2        = nn.Conv2d(in_channels=6, out_channels=3, kernel_size=(3, 3),padding=1)\n",
    "        self.sigmoid      = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.conv3d1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.conv3d2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        \n",
    "    def forward(self, ip):\n",
    "        \n",
    "#         temp = self.globalmpool1(ip)\n",
    "#         temp = temp.view( (-1, 3, 360, 640))\n",
    "        \n",
    "        temp = self.relu( self.conv3d1(ip) )\n",
    "        out  = self.mpool3d( temp  )\n",
    "        #print(ip.shape, temp.shape, out.shape)\n",
    "    \n",
    "        temp1 = out\n",
    "#         temp1 = self.globalmpool2(out)\n",
    "#         temp1 = temp1.view( (-1, 6, 180, 320) )\n",
    "\n",
    "        out = self.mpool3d( self.relu( self.conv3d2(out) ) )\n",
    "        out = out.view((-1,8,90,160))\n",
    "\n",
    "        out = self.parNet(out)\n",
    "        \n",
    "        out = self.upsample(out) \n",
    "        out = self.relu( self.conv1(out) + temp1[:, :, int(temp1.shape[2]/2), :, :] )\n",
    "\n",
    "        out = self.upsample(out) + temp[:, :, int(temp.shape[2]/2), :, :]\n",
    "        out = self.conv2(out) \n",
    "\n",
    "        return self.sigmoid( out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be54a72a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac550ca",
   "metadata": {
    "code_folding": [
     0,
     44,
     69
    ]
   },
   "outputs": [],
   "source": [
    "# Scripts to train, predict and a pipeline to convert original video to denoised video\n",
    "\n",
    "def train(model, dataset, optimizer=None, lossFunction=None, numEpochs=10, val_split=0.05, savePath=''):\n",
    "    \n",
    "    if optimizer == None or lossFunction == None:\n",
    "        raise Exception('Missing Parameters')\n",
    "    \n",
    "    loaderObject = dataset #DataLoader(device)\n",
    "    \n",
    "    trainLosses, valLosses = [], []\n",
    "    for epoch in range(numEpochs):\n",
    "        \n",
    "        model.train()\n",
    "        videoLosses = []\n",
    "        for offset in tq.tqdm(range(100)):\n",
    "            for index in range(0, 45, 5):\n",
    "                xTrain, yTrain= loaderObject.loadBatch( (index, index + 5 ), offset)\n",
    "                optimizer.zero_grad()\n",
    "                yhat = model(xTrain)\n",
    "                currloss = lossFunction(yTrain, yhat)\n",
    "                videoLosses.append(currloss.item())\n",
    "                \n",
    "                currloss.backward()\n",
    "                torch.nn.utils.clip_grad_value_(model.parameters(), 1)\n",
    "                optimizer.step()\n",
    "\n",
    "        epochTrainLoss = np.mean(videoLosses)\n",
    "        torch.save(model.state_dict(), savePath + '/save_' + str(10 + epoch) + '_' + str(np.round(epochTrainLoss, decimals=4)) + '.pt')\n",
    "        trainLosses.append( epochTrainLoss )\n",
    "                \n",
    "                 \n",
    "        model.eval()\n",
    "        videoLosses = []\n",
    "        for offset in tq.tqdm(range(100)):\n",
    "            for index in range(45, 50, 5):\n",
    "                xVal, yVal = loaderObject.loadBatch( (index, index + 5 ), offset)\n",
    "                with torch.no_grad():\n",
    "                    yhat = model(xTrain)\n",
    "                    currloss = lossFunction(yhat, yTrain)\n",
    "                    videoLosses.append(currloss.item())\n",
    "        valLosses.append( np.mean(videoLosses) )\n",
    "        print('Epoch ', str(epoch), ' completed : TrainLoss/ValLoss', \n",
    "             np.round(trainLosses[-1], 6),'/', np.round(valLosses[-1], 6) )\n",
    "            \n",
    "    return trainLosses, valLosses\n",
    "\n",
    "def predict(model, inputLocation, outputLocation=None):\n",
    "    import os\n",
    "    try:\n",
    "        os.makedirs(outputLocation)\n",
    "    except:\n",
    "        pass\n",
    "    tobj = TestLoader(inputLocation, device)\n",
    "    frameCount = tobj.getCountOfFrames()\n",
    "    output = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(frameCount):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output.append( reformatTensor2Image( torch.squeeze(model(tobj.loadUnit(i) )) )  )\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    if outputLocation != None:\n",
    "        for i in range(frameCount):\n",
    "            cv2.imwrite(outputLocation + '/' + str(i).zfill(5) + '.jpg', \n",
    "                        cv2.resize( cv2.cvtColor(output[i]*255, cv2.COLOR_RGB2BGR ), (1280, 720)) )\n",
    "    print(\"Denoising Complete, Time Taken : \", end-start)\n",
    "    return output\n",
    "\n",
    "def pipeLinePredictor(model, inputLocation, outputLocation):\n",
    "    getFrames(inputLocation, 'temporaryFrames')\n",
    "    predict(model, 'temporaryFrames', 'temporaryOutFrames')\n",
    "    makeVideo('temporaryOutFrames', outputLocation)\n",
    "    \n",
    "    print(\"Generating Video. Cleaning Files\")\n",
    "    shutil.rmtree('temporaryFrames')\n",
    "    shutil.rmtree('temporaryOutFrames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d8b4ca4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4427c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0190d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Information of the directories stored in the csv files\n",
    "\n",
    "dataDirectory = 'DeepVideoDeblurring_Dataset/quantitative_datasets/'\n",
    "dataInfo = pd.read_csv(dataDirectory + 'Info.csv', index_col=0)\n",
    "testDirectory = 'DeepVideoDeblurring_Dataset/qualitative_datasets/'\n",
    "testInfo = pd.read_csv(testDirectory + 'Info.csv', index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53da7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset in the memory,\n",
    "# Currently the loader is set to load all videos in 360p resolution in RGB color\n",
    "# Alter the Dataloader as required\n",
    "\n",
    "dobj = DataLoader(device)\n",
    "dobj.loadVideo(dataDirectory, dataInfo, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f0347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a67ee9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise the model and load a saved weight\n",
    "model = DenoiserStackConv().to(device)\n",
    "model.load_state_dict(torch.load( 'con3dWeight.pt') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff9c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "544417a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a batch to test if the model is working\n",
    "\n",
    "x, y = dobj.loadBatch((0, 5), 0)\n",
    "ypred = model(x)\n",
    "ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b92ea39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12907658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the loss functions and optimizers\n",
    "\n",
    "lossfn = nn.MSELoss()\n",
    "optSGD = torch.optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.1)\n",
    "optRMS = torch.optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "optAdam = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775db7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train, change optimizer and epochs as required, can write your own training script\n",
    "# Alter the training script above to adjust the validation and training sizes.\n",
    "\n",
    "history = train(model, \n",
    "                dobj, \n",
    "                optimizer=optSGD, \n",
    "                lossFunction=lossfn, \n",
    "                numEpochs=5, \n",
    "                savePath = 'stackConv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad51238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predicitng and saving the images for qualitiative dataset from Deep Video Deblurring Dataset\n",
    "\n",
    "for dr in tq.tqdm( testInfo['dirname'] ):\n",
    "    predict(model, testDirectory + dr + '/input', testDirectory + dr + '/conv3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f2ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51032b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "printDiagram(model, x, 'stackConv.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d97dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can convert a noised video to clear video\n",
    "pipeLinePredictor(model, 'input.mp4', 'out.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a29dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84aa5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2490c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5294f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
